#numpy_mlp 
#neg_slope : 0.02
#learning_rate : 0.002
#batch_size : 200
#hidden_units : [100]
#max_steps : 1500
#epoch batch max_steps loss train_acc test_acc test_loss
0 0 1500 2.303 0.065 0.097 2.303
0 100 1500 1.759 0.350 0.364 1.771
0 200 1500 1.690 0.445 0.399 1.678
1 300 1500 1.591 0.425 0.415 1.672
1 400 1500 1.653 0.415 0.426 1.693
1 500 1500 1.588 0.465 0.424 1.633
2 600 1500 1.474 0.505 0.449 1.573
2 700 1500 1.403 0.515 0.437 1.603
3 800 1500 1.547 0.445 0.436 1.601
3 900 1500 1.556 0.450 0.464 1.503
3 1000 1500 1.508 0.455 0.485 1.476
4 1100 1500 1.470 0.490 0.464 1.548
4 1200 1500 1.727 0.440 0.462 1.521
5 1300 1500 1.263 0.585 0.479 1.493
5 1400 1500 1.291 0.560 0.472 1.555
5 1500 1500 1.640 0.425 0.438 1.622
